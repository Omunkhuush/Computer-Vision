{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    def forward(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out= x * y\n",
    "        return out \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        return dx, dy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1 \n",
    "        dy = dout * 1 \n",
    "        return dx, dy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150 \n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "#layer \n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward\n",
    "apple_price = mul_apple_layer.forward(apple,apple_num) \n",
    "orange_price = mul_orange_layer.forward(orange, orange_num) \n",
    "all_price = add_apple_orange_layer.forward(apple_price,orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward \n",
    "dprice = 1 \n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)  \n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dorange, dorange_num =  mul_orange_layer.backward(dorange_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price: 715\n",
      "dApple: 2.2\n",
      "dApple_num: 110\n",
      "dOrange: 3.3000000000000003\n",
      "dOrange_num: 165\n",
      "dTax: 650\n"
     ]
    }
   ],
   "source": [
    "print(\"price:\", int(price))\n",
    "print(\"dApple:\", dapple)\n",
    "print(\"dApple_num:\", int(dapple_num))\n",
    "print(\"dOrange:\", dorange)\n",
    "print(\"dOrange_num:\", int(dorange_num))\n",
    "print(\"dTax:\", dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "### параметрүүд\n",
    "# Хэдэн удаа оролтын датагаар моделийг сургах\n",
    "EPOCH = 10          \n",
    "# 1 удаад оруулах оролтын датаны хэмжээ\n",
    "BATCH_SIZE = 50\n",
    "# Learning Rate\n",
    "LR = 0.001              \n",
    "# MNIST датаг татах эсэх \n",
    "DOWNLOAD_MNIST = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist digits dataset\n",
    "batch_size = 32\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     \n",
    "    # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    \n",
    "    # torch.FloatTensor of shape (Color x Height x Width) and \n",
    "    # normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,                        \n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist', train=False,\n",
    "                                       download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./mnist/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x1500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot example\n",
    "fig = plt.figure(figsize=(9, 15))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n",
    "                    wspace=0.05)\n",
    "\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(1, 9, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(train_data.data[i].numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.data.size())                 # (60000, 28, 28)\n",
    "print(train_data.targets.size())               # (60000)\n",
    "     \n",
    "torch.Size([60000, 28, 28])\n",
    "torch.Size([60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.FloatTensor)[:2000]/255.   \n",
    "# shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.targets[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=None, padding=0),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=None, padding=0),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=128*7*7,out_features=50, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(in_features=50, out_features=10, bias=True)\n",
    "        ) \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        output = self.fc(x)\n",
    "        return output, x\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6272, out_features=50, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.25, inplace=False)\n",
      "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN().cuda()\n",
    "print(cnn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN                                      [1, 10]                   --\n",
      "├─Sequential: 1-1                        [1, 128, 7, 7]            --\n",
      "│    └─0.weight                                                    ├─288\n",
      "│    └─0.bias                                                      ├─32\n",
      "│    └─3.weight                                                    ├─18,432\n",
      "│    └─3.bias                                                      ├─64\n",
      "│    └─6.weight                                                    ├─73,728\n",
      "│    └─6.bias                                                      └─128\n",
      "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           320\n",
      "│    │    └─weight                                                 ├─288\n",
      "│    │    └─bias                                                   └─32\n",
      "│    └─ReLU: 2-2                         [1, 32, 28, 28]           --\n",
      "│    └─MaxPool2d: 2-3                    [1, 32, 14, 14]           --\n",
      "│    └─Conv2d: 2-4                       [1, 64, 14, 14]           18,496\n",
      "│    │    └─weight                                                 ├─18,432\n",
      "│    │    └─bias                                                   └─64\n",
      "│    └─ReLU: 2-5                         [1, 64, 14, 14]           --\n",
      "│    └─MaxPool2d: 2-6                    [1, 64, 7, 7]             --\n",
      "│    └─Conv2d: 2-7                       [1, 128, 7, 7]            73,856\n",
      "│    │    └─weight                                                 ├─73,728\n",
      "│    │    └─bias                                                   └─128\n",
      "│    └─ReLU: 2-8                         [1, 128, 7, 7]            --\n",
      "├─Sequential: 1-2                        [1, 10]                   --\n",
      "│    └─0.weight                                                    ├─313,600\n",
      "│    └─3.weight                                                    ├─500\n",
      "│    └─3.bias                                                      └─10\n",
      "│    └─Linear: 2-9                       [1, 50]                   313,600\n",
      "│    │    └─weight                                                 └─313,600\n",
      "│    └─ReLU: 2-10                        [1, 50]                   --\n",
      "│    └─Dropout: 2-11                     [1, 50]                   --\n",
      "│    └─Linear: 2-12                      [1, 10]                   510\n",
      "│    │    └─weight                                                 ├─500\n",
      "│    │    └─bias                                                   └─10\n",
      "==========================================================================================\n",
      "Total params: 406,782\n",
      "Trainable params: 406,782\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 7.81\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 1.63\n",
      "Estimated Total Size (MB): 1.98\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN                                      [1, 10]                   --\n",
      "├─Sequential: 1-1                        [1, 128, 7, 7]            --\n",
      "│    └─0.weight                                                    ├─288\n",
      "│    └─0.bias                                                      ├─32\n",
      "│    └─3.weight                                                    ├─18,432\n",
      "│    └─3.bias                                                      ├─64\n",
      "│    └─6.weight                                                    ├─73,728\n",
      "│    └─6.bias                                                      └─128\n",
      "│    └─Conv2d: 2-1                       [1, 32, 28, 28]           320\n",
      "│    │    └─weight                                                 ├─288\n",
      "│    │    └─bias                                                   └─32\n",
      "│    └─ReLU: 2-2                         [1, 32, 28, 28]           --\n",
      "│    └─MaxPool2d: 2-3                    [1, 32, 14, 14]           --\n",
      "│    └─Conv2d: 2-4                       [1, 64, 14, 14]           18,496\n",
      "│    │    └─weight                                                 ├─18,432\n",
      "│    │    └─bias                                                   └─64\n",
      "│    └─ReLU: 2-5                         [1, 64, 14, 14]           --\n",
      "│    └─MaxPool2d: 2-6                    [1, 64, 7, 7]             --\n",
      "│    └─Conv2d: 2-7                       [1, 128, 7, 7]            73,856\n",
      "│    │    └─weight                                                 ├─73,728\n",
      "│    │    └─bias                                                   └─128\n",
      "│    └─ReLU: 2-8                         [1, 128, 7, 7]            --\n",
      "├─Sequential: 1-2                        [1, 10]                   --\n",
      "│    └─0.weight                                                    ├─313,600\n",
      "│    └─3.weight                                                    ├─500\n",
      "│    └─3.bias                                                      └─10\n",
      "│    └─Linear: 2-9                       [1, 50]                   313,600\n",
      "│    │    └─weight                                                 └─313,600\n",
      "│    └─ReLU: 2-10                        [1, 50]                   --\n",
      "│    └─Dropout: 2-11                     [1, 50]                   --\n",
      "│    └─Linear: 2-12                      [1, 10]                   510\n",
      "│    │    └─weight                                                 ├─500\n",
      "│    │    └─bias                                                   └─10\n",
      "==========================================================================================\n",
      "Total params: 406,782\n",
      "Trainable params: 406,782\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 7.81\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 1.63\n",
      "Estimated Total Size (MB): 1.98\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "stats = summary(cnn,(1,1,28,28),verbose=2)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR                                                                                                                                                     )   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization\n",
    "from matplotlib import cm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla()\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer');\n",
    "    plt.show(); \n",
    "    #plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x2cbb45df6d0>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0 | loss:2.2965 | test accuracy: 0.10\n",
      "step:400 | loss:2.3204 | test accuracy: 0.55\n",
      "step:800 | loss:1.5069 | test accuracy: 0.48\n",
      "step:1200 | loss:2.3405 | test accuracy: 0.10\n",
      "step:1600 | loss:2.4264 | test accuracy: 0.10\n",
      "step:0 | loss:2.4421 | test accuracy: 0.09\n",
      "step:400 | loss:2.3260 | test accuracy: 0.12\n",
      "step:800 | loss:2.3273 | test accuracy: 0.10\n",
      "step:1200 | loss:2.4417 | test accuracy: 0.11\n",
      "step:1600 | loss:2.3260 | test accuracy: 0.11\n",
      "step:0 | loss:2.3440 | test accuracy: 0.10\n",
      "step:400 | loss:2.3391 | test accuracy: 0.11\n",
      "step:800 | loss:2.3203 | test accuracy: 0.10\n",
      "step:1200 | loss:2.2540 | test accuracy: 0.10\n",
      "step:1600 | loss:2.2743 | test accuracy: 0.11\n",
      "step:0 | loss:2.3360 | test accuracy: 0.11\n",
      "step:400 | loss:2.2716 | test accuracy: 0.11\n",
      "step:800 | loss:2.3099 | test accuracy: 0.10\n",
      "step:1200 | loss:2.3920 | test accuracy: 0.12\n",
      "step:1600 | loss:2.3002 | test accuracy: 0.10\n",
      "step:0 | loss:2.3333 | test accuracy: 0.11\n",
      "step:400 | loss:2.3577 | test accuracy: 0.12\n",
      "step:800 | loss:2.4002 | test accuracy: 0.10\n",
      "step:1200 | loss:2.4150 | test accuracy: 0.10\n",
      "step:1600 | loss:2.3336 | test accuracy: 0.09\n",
      "step:0 | loss:2.3271 | test accuracy: 0.10\n",
      "step:400 | loss:2.3203 | test accuracy: 0.10\n",
      "step:800 | loss:2.3384 | test accuracy: 0.09\n",
      "step:1200 | loss:2.3179 | test accuracy: 0.10\n",
      "step:1600 | loss:2.3393 | test accuracy: 0.11\n",
      "step:0 | loss:2.3103 | test accuracy: 0.12\n",
      "step:400 | loss:2.3868 | test accuracy: 0.11\n",
      "step:800 | loss:2.3429 | test accuracy: 0.10\n",
      "step:1200 | loss:2.2470 | test accuracy: 0.12\n",
      "step:1600 | loss:2.2836 | test accuracy: 0.11\n",
      "step:0 | loss:2.3459 | test accuracy: 0.11\n",
      "step:400 | loss:2.3335 | test accuracy: 0.11\n",
      "step:800 | loss:2.3187 | test accuracy: 0.12\n",
      "step:1200 | loss:2.3176 | test accuracy: 0.10\n",
      "step:1600 | loss:2.4348 | test accuracy: 0.09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[219], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m best_accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCH):\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mfor\u001b[39;00m step, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      7\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad\n\u001b[0;32m      8\u001b[0m         \u001b[39m# clear gradients for this training step\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\Project\\DLUB\\.dlubEnv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\Project\\DLUB\\.dlubEnv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\Project\\DLUB\\.dlubEnv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1324\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1325\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1326\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1327\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\Project\\DLUB\\.dlubEnv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1151\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1164\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1165\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[0;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[1;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:335\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_got_empty_message \u001b[39mor\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             _winapi\u001b[39m.\u001b[39mPeekNamedPipe(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(wait([\u001b[39mself\u001b[39;49m], timeout))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:884\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 ready_objects\u001b[39m.\u001b[39madd(o)\n\u001b[0;32m    882\u001b[0m                 timeout \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 884\u001b[0m     ready_handles \u001b[39m=\u001b[39m _exhaustive_wait(waithandle_to_obj\u001b[39m.\u001b[39;49mkeys(), timeout)\n\u001b[0;32m    885\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[39m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m ov \u001b[39min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py:816\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    814\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[0;32m    815\u001b[0m \u001b[39mwhile\u001b[39;00m L:\n\u001b[1;32m--> 816\u001b[0m     res \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mWaitForMultipleObjects(L, \u001b[39mFalse\u001b[39;49;00m, timeout)\n\u001b[0;32m    817\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    818\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad\n",
    "        # clear gradients for this training step\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        output =  cnn(x)[0]\n",
    "        loss = loss_func(output,y)    \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #Visualization\n",
    "        if step % 400 == 0:\n",
    "            test_output, last_layer = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data\n",
    "            accuracy = (pred_y == test_y).sum().item() / float(test_y.size(0))\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                torch.save(cnn,'best_model.pt')\n",
    "                torch.save(cnn.state_dict(),'best_model_parameters.pt')\n",
    "            print('step:{}'.format(step), '| loss:{:.4f}'.format(loss.data), '| test accuracy: {:.2f}'.format(accuracy) ) \n",
    "\n",
    "            # # Visualization of trained flatten layer (T-SNE)\n",
    "            # tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "            # plot_only = 500\n",
    "            # low_dim_embs = tsne.fit_transform(last_layer.cpu().data.numpy()[:plot_only, :])\n",
    "            # labels = test_y.cpu().numpy()[:plot_only]\n",
    "            # plot_with_labels(low_dim_embs, labels)\n",
    "#plt.ioff()\n",
    "print('best accuracy: {:.2f}'.format(best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 23 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        # calculate outputs by running images through the network \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = cnn(x)[0]\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        predicted = torch.max(outputs.data, 1)[1]\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNN                                      --\n",
      "├─Sequential: 1-1                        --\n",
      "│    └─Conv2d: 2-1                       416\n",
      "│    └─ReLU: 2-2                         --\n",
      "│    └─MaxPool2d: 2-3                    --\n",
      "│    └─Conv2d: 2-4                       12,832\n",
      "│    └─ReLU: 2-5                         --\n",
      "│    └─MaxPool2d: 2-6                    --\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Linear: 2-7                       78,400\n",
      "│    └─ReLU: 2-8                         --\n",
      "│    └─Dropout: 2-9                      --\n",
      "│    └─Linear: 2-10                      510\n",
      "=================================================================\n",
      "Total params: 92,158\n",
      "Trainable params: 92,158\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# model = torch.load('./best_model.pt')\n",
    "# model.eval()\n",
    "# model = model.to(device)\n",
    "# stat = summary(model)\n",
    "# print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tensor([[-1.6751e+01, -2.1256e+01, -1.0370e+01,  1.4442e+01, -2.6685e+01,\n",
      "          2.8183e+00, -3.8260e+01,  4.2409e+01, -3.9042e+00,  1.5009e+01],\n",
      "        [ 6.1046e+00,  9.1853e+00,  1.4567e+01, -5.2477e+00, -9.0629e+00,\n",
      "         -1.3940e+01,  1.0833e+01, -1.7073e+01, -5.0005e+00, -1.2094e+01],\n",
      "        [-1.4559e+00,  1.3899e+01, -3.6330e+00, -8.0635e+00, -1.9468e+00,\n",
      "         -7.4585e+00,  4.9790e+00, -9.8239e+00,  1.7165e+00, -8.8345e+00],\n",
      "        [ 6.3657e+00, -2.5402e+00, -3.3042e+00,  1.4555e+00, -7.4057e+00,\n",
      "          1.4898e+00, -1.7071e+00, -1.5841e+00,  1.5381e+00, -4.4349e-01],\n",
      "        [-7.2175e+00, -6.7089e+00,  2.3904e+00, -9.4411e+00,  1.1990e+01,\n",
      "         -4.5355e-01, -2.0105e+00, -3.5687e-01, -2.5330e+00,  8.4313e+00],\n",
      "        [-8.7683e-01,  1.3677e+01, -2.8439e+00, -8.0400e+00, -1.9545e+00,\n",
      "         -7.5515e+00,  4.4446e+00, -9.9268e+00,  2.1942e+00, -1.0020e+01],\n",
      "        [-3.8972e+00, -1.7028e+00, -5.0495e-01, -2.3627e+00,  3.0419e+00,\n",
      "          6.4679e-01, -2.0913e+00, -2.1250e-01, -6.6272e-01,  2.3234e+00],\n",
      "        [-2.7215e+00, -1.0958e+00, -7.1738e-01, -2.5317e+00,  2.2287e+00,\n",
      "          6.0946e-01, -1.2029e+00, -9.9521e-01, -1.7543e-02,  1.1122e+00],\n",
      "        [-3.4534e-01,  3.2667e-01, -3.1633e-01,  1.2981e-01,  1.2612e-01,\n",
      "          3.6527e-01, -5.3096e-01, -3.0325e-01,  4.8249e-01, -2.8880e-01],\n",
      "        [-3.2550e+00, -3.0455e+00, -3.1212e+00,  2.2767e-01, -1.1258e+00,\n",
      "          2.5167e+00, -4.9489e+00,  3.5660e+00,  3.5638e-01,  3.2176e+00],\n",
      "        [ 1.4365e+01, -8.0822e+00, -3.6033e+00,  1.1375e+00, -1.8565e+01,\n",
      "          3.0169e+00, -3.9299e+00, -8.6629e+00,  5.0255e+00, -4.2603e+00],\n",
      "        [ 1.8760e+00, -1.1690e+00, -3.0869e+00, -4.0295e+00, -5.6757e+00,\n",
      "         -4.6070e-01,  5.3687e+00, -6.4542e+00, -1.7820e+00, -1.4506e+00],\n",
      "        [-4.3488e+00, -3.9637e+00, -2.1768e+00, -2.9466e+00,  1.8983e+00,\n",
      "          1.8426e+00, -4.3733e+00,  1.1033e+00,  1.5791e-01,  3.8580e+00],\n",
      "        [ 1.0889e+01, -7.6511e+00, -4.4101e+00,  1.6284e-01, -1.3170e+01,\n",
      "          3.3285e+00, -2.1678e+00, -5.2965e+00,  4.5923e+00, -1.5871e+00],\n",
      "        [ 2.2903e-01,  3.9300e+00, -7.6087e-01, -9.2330e-01, -1.5297e+00,\n",
      "         -2.0627e+00, -8.5898e-01, -2.9415e+00,  2.4887e-01, -2.0469e+00],\n",
      "        [ 5.4272e-01, -7.9994e+00, -6.0522e-01,  7.3832e-01, -7.8918e+00,\n",
      "          4.7496e+00, -1.1222e+00, -6.2884e+00,  2.6143e-01, -4.6311e-01],\n",
      "        [-5.0159e+00, -5.1125e+00,  1.2222e+00, -5.2594e-02, -3.3715e+00,\n",
      "         -1.9267e+00, -8.8183e+00,  6.3707e+00,  8.4556e-01,  6.0296e+00],\n",
      "        [-9.9008e+00, -2.1525e+01, -1.2277e+01,  1.1675e+01, -2.2648e+01,\n",
      "          7.1419e+00, -3.2304e+01,  3.4864e+01, -2.2124e+00,  1.2730e+01],\n",
      "        [-1.6889e-02,  5.5532e-01,  3.5922e-01, -3.8192e-01, -3.9669e-01,\n",
      "         -3.2497e-01,  5.8433e-01, -1.1437e+00, -1.5470e-01, -1.3167e-02],\n",
      "        [-6.0529e+00, -6.4769e+00, -2.5410e-01, -8.6648e+00,  9.3172e+00,\n",
      "          1.7192e+00, -1.4790e+00, -3.7014e+00, -2.9270e+00,  6.5230e+00],\n",
      "        [-2.8991e+00, -2.1288e+00, -2.7706e+00,  8.7060e-01, -1.2894e+00,\n",
      "          2.2831e+00, -3.9660e+00,  3.0135e+00,  3.1356e-01,  2.2583e+00],\n",
      "        [ 9.2180e-01, -1.9726e+00, -2.5204e+00, -5.2923e+00, -4.2206e+00,\n",
      "          4.1484e-01,  5.7493e+00, -7.1574e+00, -1.6134e+00, -1.3415e+00],\n",
      "        [ 1.3906e+00,  8.8399e-01, -1.1856e+00, -4.7849e+00, -3.7897e+00,\n",
      "         -1.8054e+00,  6.7574e+00, -7.9048e+00, -1.8125e+00, -2.9902e+00],\n",
      "        [ 1.3997e+00, -1.1354e+01, -4.4954e+00, -2.6690e+00, -7.0046e+00,\n",
      "          9.7621e+00, -6.0462e+00, -5.8693e+00,  2.1035e+00, -3.8434e-01],\n",
      "        [-3.5916e+00, -1.8476e+00, -1.6364e+00, -4.6652e+00,  4.4340e+00,\n",
      "          1.5310e+00, -4.4017e-01, -1.6749e+00, -2.5592e-01,  2.0593e+00],\n",
      "        [ 2.3046e+00, -1.1461e+00, -1.4497e+00,  5.4446e-01, -2.5532e+00,\n",
      "          7.1748e-01, -1.5600e+00, -1.8708e-01,  1.0231e+00,  3.6460e-01],\n",
      "        [-7.1732e+00, -1.7650e+01, -1.1425e+01,  8.9595e+00, -1.4971e+01,\n",
      "          6.6977e+00, -2.5186e+01,  2.6344e+01, -2.0730e+00,  1.1326e+01],\n",
      "        [-6.9951e+00, -7.1293e+00,  1.4567e+00, -1.3896e+01,  1.2152e+01,\n",
      "          1.0591e+00,  9.0390e-01, -6.2048e+00, -2.3087e+00,  4.5189e+00],\n",
      "        [ 6.5478e+00, -4.0421e+00, -1.7808e+00,  1.3241e+00, -9.6160e+00,\n",
      "          1.5255e+00, -3.3153e+00, -5.8094e+00,  2.1206e+00, -2.8393e+00],\n",
      "        [-5.2394e-01,  1.9357e+00,  9.5066e-01,  1.0440e+00, -1.9631e+00,\n",
      "         -1.7029e+00, -1.2936e+00, -4.5459e-01, -2.0182e-01, -1.0721e+00],\n",
      "        [-2.0203e+00, -4.9144e-01,  3.0308e+00,  5.9151e+00, -7.7539e+00,\n",
      "         -3.2393e+00, -1.7872e+00,  2.0090e+00, -8.5399e-01, -1.7657e-01],\n",
      "        [-2.8759e-01,  7.3398e-01,  4.1855e-02,  1.7955e-01, -2.9863e-01,\n",
      "         -1.4253e-01, -5.3441e-01, -4.9350e-01,  3.3574e-01, -5.2688e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0') tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[171], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39my\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(predicted,y)\n\u001b[1;32m---> 14\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39;49m y)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy of the network on the 10000 test images: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m     16\u001b[0m     \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m correct \u001b[39m/\u001b[39m total))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "model = torch.load('./best_model.pt')\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "correct = 0\n",
    "total = 0\n",
    "for x,y in test_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    output = model(x)[0]\n",
    "    print(\"output\",output)\n",
    "    predticted = torch.max(output.data,1)[1]\n",
    "    total +=y.size(0)\n",
    "    print(predicted,y)\n",
    "    correct += (predicted == y).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 8 1 8 8 1 8 8 8 8] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "# print 10 predictions from test data\n",
    "test_output, _ = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].cpu().data.numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].cpu().numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-1.8721, -2.1238, -1.9910, -1.1325, -1.6394, -1.0231, -1.8737, -1.3792,\n",
       "        -2.2135, -1.8976, -1.9058, -2.1026, -1.8898, -2.1103, -2.0814, -1.8860],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.conv[0].weight.grad[0]\n",
    "cnn.conv[0].weight[0]\n",
    "cnn.conv[0].bias.grad\n",
    "cnn.conv[0].bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".DLUB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
